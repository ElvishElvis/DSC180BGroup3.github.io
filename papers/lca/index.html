<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LCA-on-the-Line</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            
            <h1 class="title is-1 publication-title"><em>LCA-on-the-Line</em> : Benchmarking Out of Distribution Generalization with Class Taxonomies
            </h1>
            <h2 class="title is-3 publication-title"> <span style="color: blue;"><a href="https://icml.cc/virtual/2024/oral/35543" target="_blank">ICML 2024 (Oral Presentation)</a></span></h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/elvishelvisshi/" target="_blank">Jia Shi</a><sup>1</sup>,</span>
                <a href="https://ggare-cmu.github.io/" target="_blank"> Gautam Gare </a><sup>1</sup>,</span>
                <a href="https://jinjint.github.io/" target="_blank"> Jinjin Tian </a><sup>1</sup>,</span>
                <a href="https://www.linkedin.com/in/siqi-chai/" target="_blank"> Siqi Chai </a><sup>1</sup>,</span>
                <a href="http://linzhiqiu.github.io" target="_blank">Zhiqiu Lin</a><sup>1</sup>,</span>
                <a href="https://arunbalajeev.github.io/" target="_blank">Arun Vasudevan</a><sup>1</sup>,</span>
                <br>
                <a href="https://www.linkedin.com/in/di-feng-2013/" target="_blank">Di Feng</a><sup>2,3</sup>,</span>
                <a href="https://www.francescoferroni.com/" target="_blank">Francesco Ferroni</a><sup>2,4</sup>,</span>
                <a href="https://aimerykong.github.io/" target="_blank">Shu Kong</a><sup>5,6</sup>
              
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">CMU<sup>1</sup>&nbsp;&nbsp&nbsp;&nbsp (Work done at) Argo AI GmbH<sup>2</sup>&nbsp;&nbsp&nbsp;&nbsp (Now at) Apple<sup>3</sup>&nbsp;&nbsp&nbsp;&nbsp (Now at) Nvidia<sup>4</sup>&nbsp;&nbsp&nbsp;&nbsp Texas A&M University<sup>5</sup>&nbsp;&nbsp&nbsp;&nbsp University of Macau<sup>6</sup><br></span>
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2407.16067" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/ElvishElvis/LCA-on-the-line" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="ICML24_LCA_poster.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-image"></i>
                    </span>
                    <span>Poster</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="ICML2024_LCA-on-the-line_slide.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                     <i class="fas fa-images"></i>
                    </span>
                    <span>Slide</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://slideslive.com/39022038/lcaontheline-benchmarking-out-of-distribution-generalization-with-class-taxonomies?ref=speaker-89432" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
                We tackle the challenge of predicting models' Out-of-Distribution (OOD) performance using in-distribution (ID) measurements without requiring OOD data. Existing evaluations with ``Effective robustness'', which use ID accuracy as an indicator of OOD accuracy, encounter limitations when models are trained with diverse supervision and distributions, such as class labels <i>(Vision Models, VMs, on ImageNet)</i> and textual descriptions <i>(Visual-Language Models, VLMs, on LAION)</i>. VLMs often generalize better to OOD data than VMs despite having similar or lower ID performance. To improve the prediction of models' OOD performance from ID measurements, we introduce the <i>Lowest Common Ancestor (LCA)-on-the-Line</i> framework. This approach revisits the established concept of LCA distance, which measures the hierarchical distance between labels and predictions within a predefined class hierarchy, such as WordNet. We assess 75 models using ImageNet as the ID dataset and five significantly shifted OOD variants, uncovering a strong linear correlation between ID LCA distance and OOD top-1 accuracy. Our method provides a compelling alternative for understanding why VLMs tend to generalize better. Additionally, we propose a technique to construct a taxonomic hierarchy on any dataset using K-means clustering, demonstrating that LCA distance is robust to the constructed taxonomic hierarchy. Moreover, we demonstrate that aligning model predictions with class taxonomies, through soft labels or prompt engineering, can enhance model generalization.
            </p>
          </div>
        </div>
      </div>
      <img src="./images/neck.png" alt="why lca works"
                style="width: 750px; height: auto; display: block; margin: 0 auto;">
    </div>
  </section>
  <!-- End paper abstract -->




  <!-- Method Overview -->
  <section class="section hero is-light2">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3">How to calculate LCA distance</h2>
          <div class="content has-text-justified">

            <div class="item">
              <p style="text-align: justify; font-size: 16px; line-height: 1.5; margin-top: 10px; color: #333;">
                Our method estimates a model’s generalization based on the in-distribution semantic severity of its mistakes. We use the 'Lowest Common Ancestor' (LCA) distance to rank the distance between the model’s prediction and the ground-truth class within a predefined taxonomic hierarchy, such as WordNet. The LCA distance is proportional to the shortest path from the prediction to the ground-truth class in the hierarchy.</p>
              </p>
            </div>
          </div>
        </div>
      </div>
      <!-- Your image here -->
      <img src="./images/lca_calculate.png" alt="LCA distance adopted from hierarchical distance"
      style="width: 850px; height: auto; display: block; margin: 0 auto;">
    </div>
  </section>
  <!-- End Method Overview -->


  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3"> LCA distance robustly predict models' OOD performance </h2>
          <div class="content has-text-justified">

            <div class="item">
              <p style="text-align: justify; font-size: 16px; line-height: 1.5; margin-top: 10px; color: #333;">
                 We show that LCA distance, a metric measuring prediction performance with respect to an ontology/hierarchy on in-distribution (ID) data, can robustly predict the model's out-of-distribution (OOD) performance. It unifies Vision Models (VMs) and Vision-Language Models (VLMs) across different modalities and training data sources in terms of measuring model generalization, outperforming "accuracy-on-the-line."
                 </p>
                 <p style="text-align: justify; font-size: 16px; line-height: 1.5; margin-top: 10px; color: #333;">
                 The following plot shows that LCA distance consistently achieves strong linear correlation on multiple ImageNet-OOD datasets. For VMs and VLMs, ID accuracy is not on the line, while ID LCA is on the line.
                </p>
            </div>
          </div>
        </div>
      </div>
      <!-- Your image here -->
      <img src="./images/predictor.png" alt="LCA is a strong OOD indicator"
      style="width: 850px; height: auto; display: block; margin: 0 auto;">
    </div>
  </section>


  <section class="section hero is-light2">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3"> LCA distance suggests how to improve models' generalization </h2>
          <div class="content has-text-justified">

            <div class="item">
              <p style="text-align: justify; font-size: 16px; line-height: 1.5; margin-top: 10px; color: #333;">
                 We show that LCA distance can be used as soft labels to improve models' OOD performance. The hierarchy allows exploiting class-pairwise distances in model training, and we train with cross-entropy plus soft labels loss.
                 </p>
            </div>
          </div>
        </div>
      </div>
      <!-- Your image here -->
      <img src="./images/improve_ood.png" alt="soft labels improve OOD"
      style="width: 850px; height: auto; display: block; margin: 0 auto;">
    </div>
  </section>


    <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3"> LCA distance offers insights why VLMs generalize so well </h2>
          <div class="content has-text-justified">

            <div class="item">
              <p style="text-align: justify; font-size: 16px; line-height: 1.5; margin-top: 10px; color: #333;">
                  We can construct a hierarchy by clustering per-class mean features using a foundation model like CLIP. We show that using a latent hierarchy performs as well as WordNet.
                  </p>
                  <p style="text-align: justify; font-size: 16px; line-height: 1.5; margin-top: 10px; color: #333;">
                  Using soft labels from latent hierarchies generated by VLMs yields better OOD results than VMs. That said, VLMs have a better human-aligned feature distribution, i.e., their generated labels better align with human-world ontology (WordNet).
                 </p>
            </div>
          </div>
        </div>
      </div>
      <!-- Your image here -->
      <img src="./images/vlm_insight.png" alt="soft labels improve OOD"
      style="width: 850px; height: auto; display: block; margin: 0 auto;">
    </div>
  </section>

<section class="section hero is-light2">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-full">
                <h2 class="title is-3">Conclusion:</h2>
                <div class="content">
                    <ul style="text-align: left; font-size: 16px; line-height: 1.5; margin-top: 10px; color: #333; list-style-type: none;">
                        <li style="margin-bottom: 10px;">1. LCA distance robustly predicts models' OOD performance.</li>
                        <li style="margin-bottom: 10px;">2. LCA distance suggests how to improve models' generalization.</li>
                        <li style="margin-bottom: 10px;">3. LCA distance offers insights into why VLMs generalize so well.</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</section>





  <!--BibTex citation -->
  <section class="section hero is-light" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{shilca,
  title={LCA-on-the-Line: Benchmarking Out of Distribution Generalization with Class Taxonomies},
  author={Shi, Jia and Gare, Gautam Rajendrakumar and Tian, Jinjin and Chai, Siqi and Lin, Zhiqiu and Vasudevan, Arun Balajee and Feng, Di and Ferroni, Francesco and Kong, Shu},
  booktitle={Forty-first International Conference on Machine Learning},year={2024}}
</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->



  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
